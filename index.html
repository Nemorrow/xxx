<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Shiye Lei (雷诗叶)</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Biography" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Undergraduate, SASEE, BUAA" />
<meta property="og:description" content="Undergraduate, SASEE, BUAA" />
<link rel="canonical" href="https://nemorrow.github.io/" />
<meta property="og:url" content="https://nemorrow.github.io/" />
<meta property="og:site_name" content="Shiye Lei" />
<script type="application/ld+json">
{"@type":"WebSite","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://leishiye.github.io/src/avatar-leishiye.jpg"}},"url":"https://leaveslei.github.io/","name":"Shiye Lei (雷诗叶)","description":"Undergraduate, SASEE, BUAA","headline":"Biography","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=8d70c79b53927e1d6a10210109acf95d3a00beb2">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  
  
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="https://nemorrow.github.io/">Shiye Lei</a></h1>
        
          <img src="/src/avatar-leaves.jpg" alt="Logo" />
        
        <p>
          <!--
          Mphil, USYD <br>
          -->
          Email &#58 leishiye[at]gmail[dot]com
        </p>

        <!--
        <p>
          <a href=./src/cv-leishiye.pdf>Curriculum Vitae</a><br>
          <a href=./src/transcript-leishiye.pdf>Transcript</a>
        </p>
        -->
        <!--
        
        <p class="view"><a href="https://github.com/leaveslei">View My GitHub Profile</a></p>
        
      -->
      </header>
      <section>
<!--
“We can humble as dust, not twisted like maggots.”<br>
 &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp
&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp —— Nelson Mandela
-->
<!--
<h2 id="education">Education</h2>
<ul>
  <li>
    <p><strong>Oct 2020-Present</strong>, Mphil., <strong>the University of Sydney</strong>, School of Computer Science<p>
  </li>
  <li>
    <p><strong>Feb 2019-Jun 2019</strong>, Exchange student, <strong>Universitat Politècnica de Catalunya</strong>, Facultat d'Informàtica de Barcelona<p>
  </li>
  <li>
    <p><strong>Sep 2015-Jul 2019</strong>, B. Eng., <strong>Beihang University</strong>, School of Automation Science and Electrical Engineering<p>
  </li>
</ul>
-->

<h2 id="bio">Bio</h2>
<ul>
 I am a Ph.D student in the School of Computer Science at the University of Sydney under the supervision of Prof. Dacheng Tao. Before that, I received B.Eng in Automation from <a href="https://ev.buaa.edu.cn/">Beihang University</a> and M.Phil in Computer Science from <a href="https://www.sydney.edu.au/">the University of Sydney</a> in 2019 and 2022, respectively. 
  My research interests include data-centric AI and knowledge extraction of large scale dataset.
</ul>
        
<h2 id="working-experience">Working Experience</h2>
<ul>
  <li>
    <p><strong>Dec 2020-Apr. 2022</strong>, Research Intern@JD Explore Academy, <a href="https://corporate.jd.com/home">JD.COM</a>.</p>
  </li>
  <!--
  <li>
    <p><strong>Jun 2019-Sep 2019</strong>, Research Assistant@laboratery of pattern recognition and intelligent system, supervised by <a href="https://scholar.google.com/citations?hl=zh-CN&user=IP_f-voAAAAJ">Tian Wang</a><p>
  </li>
  -->
  <li>
    <p><strong>Feb 2019-Jun 2019</strong>, Research Assistant@<a href="https://www.bsc.es/">Barcelona Computing Center</a>, supervised by <a href="https://www.bsc.es/casas-marc">Marc Casas</a>.<p>
  </li>
  <li>
    <p><strong>Oct 2018-Feb 2019</strong>, Research Intern@<a href="https://www.matrix.io/">Matrix AI Lab</a>, mentored by Youyou Jiang.</p>
</ul>
        
<!--
<h2 id="academic-performance">Academic Performance</h2>
<ul>
  <li>
    <p><strong>GPA</strong>: 3.74/4</p>
  </li>
  <li>
    <p><strong>Average Score</strong>: 90.6/100</p>
  </li>
  <li>
    <p><strong>Rank</strong>: 20/175</p>
   </li>
</ul>

<h2 id="projects">Projects</h2>
<ul>
  <li>
    <p><a href="https://github.com/LeavesLei/Refed">REFED</a>: Rib Extraction and Fracture Detection Model</p>
  </li>
  <li>
    <p><a href="https://github.com/LeavesLei/UPC-DL-lab-code">Experiment reports of deep learning</a></p>
</ul>    
-->
<h2 id="publications">Publications</h2>
<ul>
  <!--
  <li>
    <p><strong>Shiye Lei</strong>, Tian Wang*, Youyou Jiang, et al. A high performance computing method for accelerating temporal action proposal generation. <strong>2019 Chinese Automation Congress (CAC'19)</strong>, Sep.2019 (Accepted) <a href="https://arxiv.org/pdf/1906.06496v3.pdf">PDF</a></p>
  </li>
  -->
  <li><p>Haowen Chen, Fengxiang He, <strong>Shiye Lei</strong>, Dacheng Tao. <q>Spectral complexity-scaled generalisation bound of complex-valued neural networks.</q> <em>Artificial Intelligence</em>, 2023. <a href="https://nemorrow.github.io/paper/chen2023spectral.pdf">[paper]</a> <a href="https://github.com/LeavesLei/cvnn_generalization">[code]</a></p></li>
  <li><p><strong>Shiye Lei</strong>, Zhuozhuo Tu, Leszek Rutkowski, Feng Zhou, Li Shen, Fengxiang He, Dacheng Tao. &quot;Spatial-Temporal-Fusion BNN: Variational Bayesian Feature Layer.&quot; <em>arXiv preprint</em> arXiv:2112.06281, 2021.</p></li>
  <li><p>Fengxiang He*, <strong>Shiye Lei</strong>*, Jianmin Ji, and Dacheng Tao. &quot;Neural networks behave as hash encoders: An empirical study.&quot; <em>arXiv preprint</em> arXiv:2101.05490. 2021. </p></li>
* Co-first authors.
</ul>
        
<h2 id="award">Professional Activities</h2>
<ul>
  <li>
    <p><strong>Conference reviewer:</strong> NeurIPS 2023, NeurIPS 2022, ICML 2022, AISTATS 2022, ACML 2021</p>
  </li>
  <li>
    <p><strong>Journal reviewer:</strong> Machine Learning</p>
  </li>
</ul>      

<h2 id="talks">Talks</h2>
<ul>
  <li>
    <p>"Introduction on Understanding Deep Learning Experimentally." Beihang University. Oct 2021.</p>
  </li>
</ul>     
    
<!--
<h2 id="motivation">Motivation</h2>
<h4 id="encounter">Encounter</h4>
  <p>I knew the concept of mechine learning when I was a junior student and taking a relevant course. The course is not attractive at all because
    the teacher just fellow his slide without much mathematics. But I was surprised by the power of deep learnin, which like a magic box and can solve everything.</p>

<h4 id="introduction">Introduction</h4>
  <p>Who I got the introduction of mechine learning form was Youyou Jiang, my mentor when I was an intern in AI Lab, Matrix Inc. I begun to use mathematics to
     calculate lots of basic mechine learning algorithm. Then we intented a Kaggle competition(About data science) with using LightGBM. I begun to realize the power of 
     data.</p>
  <p>At work, we built REFED, which splits ribs in from CT image through open operation and then locate fracture via faster-rcnn. From the project, I knew how CNN work and
    learnt to build model with TensorFlow.</p>
<h4 id="research">Research</h4>
   <p>My research show up with my bachelor thesis, which is aim to generate action proposal in untrimmed video. I used several distributed framework to accelerate the DNN model，
      and also increased the accuracy through changing model's architecture and embedding. Ideal is not sophisticated, but tune is a big project. Partly work of my bachelor thesis
      had be translate into English and was accepted by CAC2019.</p>
<h4 id="interest">Interests</h4> 
   <p>Beyond doubt, AI, especially its application like CV or NLP, has attracted world-wide attention because of its grander prospects. But for me, what attracts me most is the
      interpretability of neural network. DNN cannot alwasy be a black box. Is there a connection between kernel size and databased?
        <a href="./mystic-kernel-size.pdf">(Mystic Kernel Size in CNN)</a>. Could RNN also be used to deal with recognition task?
        <a href="./recognize-mnist.pdf">(Recognize MNIST with RNN)</a>. How could NLP analyze the 
        interpersonal relationship?<a href="./word2vec.pdf">(Word2vec with Marvel Films' dialogues)</a>. Above all, How to find the autofit model for a specific situation?</p>
        
        <p>Maybe you will ask me, which is my favorite field？ Model. Because data is always here and is impossible to dispear. Optmization methods need to put a lot of efforts into it while a small improvement can be obtained. (In the past 50 years, back-propagation is still the 
          most reliable optmization method. But recently some new sounds came up: <a href="https://arxiv.org/pdf/1908.01580v1.pdf">THE HSIC BOTTLENECK: DEEP LEARNING WITHOUT BACK-PROPAGATION</a>)
          As for as I am concerned, Model is the most effective way to get an improvement.</p>
-->
<!--
<h4 id="epilogue">Epilogue</h4>
         <p>Dear professors, if you think I am no eligible for the position or you don't have enough position, feel free to reject me. Thank for taking time to consider my application.</p>
-->
<hr>
<p>(Last Update: Jun., 2023)</p>
<!--
<img src="//clustrmaps.com/map_v2.png?cl=ffffff&w=300&t=t&d=eKalq3a22evgwYnN9ZrSqOn9bWpaEaqcmdATwXCBd_g&co=2d78ad&ct=ffffff" />
-->

      </section>
      <!--
      
    -->
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    </body>
</html>
